{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56943f1-a874-4af5-8afd-dd007908418c",
   "metadata": {},
   "source": [
    "# Data collection - BBC website\n",
    "# Part 1: Episode information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5845cb78-2889-4776-b8bc-ae5f91394f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from lxml.html import parse, fromstring\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f6413-a8d6-4d0b-bc1c-e8673a3d0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The packages used on Google Colab\n",
    "\n",
    "!pip install git+https://github.com/openai/whisper.git \n",
    "!sudo apt update && sudo apt install ffmpeg\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c3b26-02fd-4265-95ab-2eb34520de87",
   "metadata": {},
   "source": [
    "## Get links of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c02ad1d-b95b-4af9-bedc-9119022e109d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASEURL = 'https://www.bbc.co.uk/programmes/b006qnmr/episodes/guide'\n",
    "\n",
    "def get_episodes(url):\n",
    "    n = 0\n",
    "    total = 111\n",
    "    while True:\n",
    "        n += 1\n",
    "        print(f\"Retrieving page {n}...\")\n",
    "        tree = parse(urlopen(url))\n",
    "        names = [\n",
    "            e.text_content() for e in tree.xpath(\"//span[@class='programme__title gamma']\")\n",
    "        ]\n",
    "        links = [\n",
    "            e.attrib[\"href\"] for e in tree.xpath(\"//div[@class='programme__body']//a\")\n",
    "        ]\n",
    "        for name, link in zip(names, links):\n",
    "            directory = {}\n",
    "            directory['names'] = name\n",
    "            directory['links'] = link\n",
    "            yield directory\n",
    "        next_page = BASEURL + str(tree.xpath(\"//a[@rel='next']/@href\")[0])\n",
    "        if not n > total:\n",
    "            url = next_page\n",
    "        else:\n",
    "            print(\"No more pages found.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0bd56-8e00-4c00-8b24-22221c1c986d",
   "metadata": {},
   "source": [
    "## Get information of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a30a58d-3e09-4c83-8da0-3d85016477c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_info(url):\n",
    "    tree = parse(urlopen(url))\n",
    "    # time\n",
    "    try:\n",
    "        time = tree.xpath(\"//div[@class='broadcast-event__time beta']/@title\")[0]\n",
    "    except:\n",
    "        time = ''\n",
    "        \n",
    "    #duration\n",
    "    duration = tree.xpath(\"//div[@class='map__intro']/p[@class='episode-panel__meta']\\\n",
    "    /text()[normalize-space()]\")[-1].strip()\n",
    "    \n",
    "    # book\n",
    "    try:\n",
    "        book = tree.xpath(\"//h3[contains(text(), 'Book Choice')]/\\\n",
    "        following-sibling::ul//h4//span[@class='title']/text()\")[0]\n",
    "    except:\n",
    "        book = ''\n",
    "    \n",
    "    # luxury\n",
    "    try:\n",
    "        luxury = tree.xpath(\"//h3[contains(text(), 'Luxury Choice')]/\\\n",
    "        following-sibling::ul//h4//span[@class='title']/text()\")[0]\n",
    "    except:\n",
    "        luxury = ''\n",
    "    \n",
    "    # favourite\n",
    "    try:\n",
    "        favourite = tree.xpath(\"//h3[contains(text(), 'Favourite')]/following-sibling::ul\\\n",
    "        //h4[@class='gamma no-margin']/span[@class='artist']/text()\")[0]\n",
    "    except:\n",
    "        favourite = ''\n",
    "    \n",
    "    # check availibility\n",
    "    download = tree.find(\"//div[@class='buttons__download']\")\n",
    "    if download is not None:\n",
    "        availibility = True\n",
    "    else:\n",
    "        availibility = False\n",
    "        \n",
    "    # check number of artists\n",
    "    artists = [e.text_content() for e in tree.xpath(\"//span[@class='artist']\")]\n",
    "    \n",
    "    return {'time':time, 'duration':duration, 'book':book, 'luxury':luxury, \\\n",
    "            'favourite':favourite, 'availibility':availibility, 'number':len(artists)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9db3b-e57c-4f85-b077-34bc6c68cc89",
   "metadata": {},
   "source": [
    "## Get information of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea92d95-e103-4ab5-93f4-99686510587e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_songs(url):\n",
    "    tree = parse(urlopen(url))\n",
    "    music_blocks = tree.xpath(\"//li[contains(@class, 'segments-list__item--music')]\")\n",
    "    artists = []\n",
    "    songs = []\n",
    "    albums = []\n",
    "    labels = []\n",
    "    \n",
    "    for block in music_blocks:  \n",
    "        # artist\n",
    "        artist_elements = block.xpath(\".//span[@class='artist']\")\n",
    "        artist_texts = [e.text_content() for e in artist_elements] if artist_elements else ' '\n",
    "        artists.extend(artist_texts)\n",
    "\n",
    "        # song\n",
    "        song_elements = block.xpath(\".//p[@class='no-margin']/span\")\n",
    "        song_texts = [e.text_content() for e in song_elements] if song_elements else ' '\n",
    "        songs.extend(song_texts)\n",
    "\n",
    "        # album\n",
    "        album_elements = block.xpath(\".//div[@class='segment__track']//em\")\n",
    "        album_texts = [e.text_content() for e in album_elements] if album_elements else ' '\n",
    "        albums.extend(album_texts)\n",
    "\n",
    "        # label\n",
    "        label_elements = block.xpath(\".//abbr[@title='Record Label']\")\n",
    "        label_texts = [e.text_content() for e in label_elements] if label_elements else ' '\n",
    "        labels.extend(label_texts)\n",
    "\n",
    "    return list(zip(artists, songs, albums, labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec141a-4dfb-4d70-8ffa-0aee1aed9a93",
   "metadata": {},
   "source": [
    "## Retrieve the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac7722-6c6b-4658-9ef0-e384ad1ad083",
   "metadata": {},
   "source": [
    "### About episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fb24b-d601-48e9-b0b0-2271ed2723f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Guests.json\", mode=\"w\") as f:\n",
    "    for item in get_episodes(BASEURL):\n",
    "        print(f\"Processing {item['names']}...\")\n",
    "        info = get_info(item['links'])\n",
    "        info['guests'] = item['names']\n",
    "        info['links'] = item['links']\n",
    "        f.write(json.dumps(info))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dc8a8-3c47-410d-9d42-d6c1baa41f51",
   "metadata": {},
   "source": [
    "### About songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1be55b-7980-48bf-9345-6e66be6f0fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"Songs.json\", mode=\"w\") as f:\n",
    "    for item in get_episodes(BASEURL):\n",
    "        print(f\"Processing {item['names']}...\")\n",
    "        for song in get_songs(item['links']):\n",
    "            song = list(song)\n",
    "            song.append(item['names'])\n",
    "            song.append(item['links'])\n",
    "            f.write(json.dumps(song))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9367b9-0778-4d7f-b06e-728cafb3d716",
   "metadata": {},
   "source": [
    "## Save as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75c591-b961-4e3a-9799-ac738c69507b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Guests.json\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e68c7-e189-416a-b0ac-89eea091fe07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('Guests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad4b40-833b-4e72-aab6-bcbbe9915d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_json(\"Songs.json\", lines=True)\n",
    "df2.columns = ['artists', 'songs', 'albums', 'labels', 'guests', 'links']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ee11a-f076-4a82-9a18-301b8719ae7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.to_csv('Songs.csv', encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd1384-816e-4448-bc46-cdb1143de509",
   "metadata": {},
   "source": [
    "# Part 2: Download Episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690245e6-9215-4d96-930e-ba2f2fb7d0b8",
   "metadata": {},
   "source": [
    "## Determine which episodes to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa26811-8343-4fe6-acef-b3077178ecf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['index'] = df.index\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['year'] = df['time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b9ee5-4dc0-4816-9910-e8ae32bdfcf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df['availibility'] == True) & (df['number'] > 0)].year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283eb80-1554-4bdb-82d0-d0bdef645d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = df.sort_values(by = 'time')\\\n",
    "            [(df['availibility'] == True) & (df['number'] > 0)]\\\n",
    "            .groupby('year').head(5)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8c0fa-0049-4c30-91ba-403fbdc55af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df.to_csv('Guests_filter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b00901-7adc-4856-990a-d642b7fdfc86",
   "metadata": {},
   "source": [
    "## Retrieve the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574058a-3edd-4488-95a5-3850d01fc824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for link, index in zip(filtered_df['links'], filtered_df['index']):\n",
    "    tree = parse(urlopen(link))\n",
    "    try:\n",
    "        file_link = [e.attrib[\"href\"] for e in tree.xpath(\"//a[@class='link-complex br-linkinvert buttons__download__link']\")][-1]\n",
    "    except:\n",
    "        file_link = [e.attrib[\"href\"] for e in tree.xpath(\"//a[@class='link-complex popup__list__item island--squashed br-secondary-bg-ontext br-secondary-bg-onbg--hover br-secondary-link-ontext--hover']\")][-1]\n",
    "    # Generate a unique file name\n",
    "    file_name = f\"file_{index}.mp3\"\n",
    "    # Download the file\n",
    "    urllib.request.urlretrieve(f\"https:{file_link}\", file_name)\n",
    "    print(f\"Downloaded {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef37c39-ca1d-4038-b052-f5706a7b3880",
   "metadata": {},
   "source": [
    "# Transcribe the audio data to text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6ee93-b7c6-42f9-b28e-84a3de423397",
   "metadata": {},
   "source": [
    "> This part was done on Google Colab, so the codes below are just some cope-paste. The idea is that set the file path of my Google drive to save the finished text data, and use the base model of Whisper to transcribe the audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561d9b6-800e-44aa-aeba-5729bd9a6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb58acf-ac14-4f6b-bcce-7bd1036ff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "!whisper 'file_xxx.mp3' --model base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3e88a-1d9a-4bff-b7fa-681a9de9b029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp file_1784.txt /content/drive/MyDrive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
